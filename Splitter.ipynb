{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script demonstrates three different text splitting techniques using LangChain:\n",
    "1. RecursiveCharacterTextSplitter\n",
    "2. TokenTextSplitter\n",
    "3. MarkdownHeaderTextSplitter\n",
    "\n",
    "Each section prints the number of resulting chunks and provides examples of how the\n",
    "text is split for clarity.\n",
    "\"\"\"\n",
    "\n",
    "import textwrap\n",
    "\n",
    "from langchain_text_splitters import (MarkdownHeaderTextSplitter,\n",
    "                                      RecursiveCharacterTextSplitter,\n",
    "                                      TokenTextSplitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "Natural language processing (NLP) is a field of artificial intelligence that focuses\n",
    "on the interaction between computers and human language. It enables computers to\n",
    "understand, interpret, and generate human language in a valuable way.\n",
    "\n",
    "The field of NLP involves many different techniques and approaches:\n",
    "1. Tokenization\n",
    "2. Part-of-speech tagging\n",
    "3. Named entity recognition\n",
    "4. Sentiment analysis\n",
    "\n",
    "Machine learning, especially deep learning, has revolutionized NLP in recent years.\n",
    "Transformers and large language models have achieved remarkable results in various\n",
    "NLP tasks.\n",
    "\"\"\"\n",
    "\n",
    "markdown_text = \"\"\"\n",
    "# Introduction to NLP\n",
    "Natural language processing is fascinating.\n",
    "\n",
    "## Basic Concepts\n",
    "Tokenization is the first step.\n",
    "\n",
    "### Advanced Topics\n",
    "Deep learning has changed everything.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Recursive Character Text Splitter Example\n",
      "Number of chunks: 7\n",
      "\n",
      "Chunk 1:\n",
      "Natural language processing (NLP) is a field of artificial\n",
      "intelligence that focuses on the interaction between\n",
      "\n",
      "Chunk 2:\n",
      "that focuses on the interaction between computers and human language\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_recursive_text_splitter(text: str, chunk_size: int = 120, chunk_overlap: int = 50) -> None:\n",
    "    \"\"\"\n",
    "    Demonstrates splitting text into chunks using RecursiveCharacterTextSplitter.\n",
    "\n",
    "    :param text: The input text to split.\n",
    "    :param chunk_size: The maximum size of each chunk.\n",
    "    :param chunk_overlap: The number of overlapping characters between consecutive chunks.\n",
    "    \"\"\"\n",
    "    print(\"\\n1. Recursive Character Text Splitter Example\")\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap, separators=[\".\", \" \"])\n",
    "    splits = splitter.split_text(text)\n",
    "    print(f\"Number of chunks: {len(splits)}\")\n",
    "\n",
    "    # Print the first two chunks as an example\n",
    "    for i, chunk in enumerate(splits[:2], start=1):\n",
    "        print(f\"\\nChunk {i}:\")\n",
    "        print(textwrap.fill(chunk, width=70))\n",
    "\n",
    "demonstrate_recursive_text_splitter(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Token Text Splitter Example\n",
      "Number of chunks: 2\n",
      "\n",
      "Chunk 1:\n",
      " Natural language processing (NLP) is a field of artificial\n",
      "intelligence that focuses on the interaction between computers and\n",
      "human language. It enables computers to understand, interpret, and\n",
      "generate human language in a valuable way.  The field of NLP involves\n",
      "many different techniques and approaches: 1. Tokenization 2. Part-of-\n",
      "speech tagging 3. Named entity recognition 4. Sentiment analysis\n",
      "Machine learning, especially deep learning, has revolutionized NLP in\n",
      "\n",
      "Chunk 2:\n",
      " NLP involves many different techniques and approaches: 1.\n",
      "Tokenization 2. Part-of-speech tagging 3. Named entity recognition 4.\n",
      "Sentiment analysis  Machine learning, especially deep learning, has\n",
      "revolutionized NLP in recent years. Transformers and large language\n",
      "models have achieved remarkable results in various NLP tasks.\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_token_text_splitter(text: str, chunk_size: int = 100, chunk_overlap: int = 50) -> None:\n",
    "    \"\"\"\n",
    "    Demonstrates splitting text into chunks based on tokens using TokenTextSplitter.\n",
    "\n",
    "    :param text: The input text to split.\n",
    "    :param chunk_size: The maximum number of tokens per chunk.\n",
    "    :param chunk_overlap: The overlap in number of tokens between consecutive chunks.\n",
    "    \"\"\"\n",
    "    print(\"\\n2. Token Text Splitter Example\")\n",
    "    splitter = TokenTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    splits = splitter.split_text(text)\n",
    "    print(f\"Number of chunks: {len(splits)}\")\n",
    "\n",
    "    # Print the first two chunks as an example\n",
    "    for i, chunk in enumerate(splits[:2], start=1):\n",
    "        print(f\"\\nChunk {i}:\")\n",
    "        print(textwrap.fill(chunk, width=70))\n",
    "\n",
    "demonstrate_token_text_splitter(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Markdown Header Text Splitter Example\n",
      "Number of chunks: 3\n",
      "\n",
      "First chunk with metadata:\n",
      "page_content='Natural language processing is fascinating.' metadata={'Header 1': 'Introduction to NLP'}\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_markdown_header_text_splitter(text: str) -> None:\n",
    "    \"\"\"\n",
    "    Demonstrates splitting a Markdown text into sections based on header levels\n",
    "    using MarkdownHeaderTextSplitter.\n",
    "\n",
    "    :param text: The Markdown text to split.\n",
    "    \"\"\"\n",
    "    print(\"\\n3. Markdown Header Text Splitter Example\")\n",
    "\n",
    "    # Define which headers to split on (and label them in metadata)\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "    ]\n",
    "    splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "    splits = splitter.split_text(text)\n",
    "\n",
    "    print(f\"Number of chunks: {len(splits)}\")\n",
    "    if splits:\n",
    "        print(\"\\nFirst chunk with metadata:\")\n",
    "        print(splits[0])\n",
    "\n",
    "demonstrate_markdown_header_text_splitter(markdown_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
